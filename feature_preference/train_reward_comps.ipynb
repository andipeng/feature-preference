{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb9baee-b622-4c37-8707-0949e11ed13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e205b6ac-00b6-4ca4-a56c-8af2711f4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "class RewardNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.reward = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.pref = nn.Linear(2, 1)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state1, state2):\n",
    "        r1 = self.reward(state1)\n",
    "        r2 = self.reward(state2)\n",
    "        comp = torch.squeeze(torch.stack([r1,r2], dim=1))\n",
    "        pref = self.pref(comp)\n",
    "        return r1, r2, pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd635ce5-260d-4f51-a206-0eabf9823d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RewardNet(\n",
       "  (reward): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (pref): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim = 18\n",
    "\n",
    "reward_net = RewardNet(state_dim)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "reward_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441683da-6be2-4173-a7bc-dab41edc92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data/train_rewards10.csv') as file_obj:\n",
    "    reader_obj = csv.reader(file_obj)\n",
    "\n",
    "    states1 = []\n",
    "    states2 = []\n",
    "    prefs = []\n",
    "    for row in reader_obj:\n",
    "        states1.append(row[0:18])\n",
    "        states2.append(row[19:37])\n",
    "        prefs.append(row[38])\n",
    "    states1 = np.array(states1,dtype=int)\n",
    "    states2 = np.array(states2,dtype=int)\n",
    "    prefs = np.array(prefs,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c6bce4-dfac-459e-9188-a428808dd0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.66004992\n",
      "[2,     1] loss: 0.65259349\n",
      "[3,     1] loss: 0.64532340\n",
      "[4,     1] loss: 0.63816702\n",
      "[5,     1] loss: 0.63115084\n",
      "[6,     1] loss: 0.62429190\n",
      "[7,     1] loss: 0.61756748\n",
      "[8,     1] loss: 0.61098850\n",
      "[9,     1] loss: 0.60451567\n",
      "[10,     1] loss: 0.59818625\n",
      "[11,     1] loss: 0.59195316\n",
      "[12,     1] loss: 0.58577091\n",
      "[13,     1] loss: 0.57968396\n",
      "[14,     1] loss: 0.57371593\n",
      "[15,     1] loss: 0.56780440\n",
      "[16,     1] loss: 0.56192696\n",
      "[17,     1] loss: 0.55603439\n",
      "[18,     1] loss: 0.55015862\n",
      "[19,     1] loss: 0.54432166\n",
      "[20,     1] loss: 0.53846997\n",
      "[21,     1] loss: 0.53262758\n",
      "[22,     1] loss: 0.52675045\n",
      "[23,     1] loss: 0.52082962\n",
      "[24,     1] loss: 0.51490206\n",
      "[25,     1] loss: 0.50896841\n",
      "[26,     1] loss: 0.50304389\n",
      "[27,     1] loss: 0.49708194\n",
      "[28,     1] loss: 0.49109301\n",
      "[29,     1] loss: 0.48502356\n",
      "[30,     1] loss: 0.47891769\n",
      "[31,     1] loss: 0.47277051\n",
      "[32,     1] loss: 0.46661115\n",
      "[33,     1] loss: 0.46041474\n",
      "[34,     1] loss: 0.45423809\n",
      "[35,     1] loss: 0.44806772\n",
      "[36,     1] loss: 0.44190255\n",
      "[37,     1] loss: 0.43579453\n",
      "[38,     1] loss: 0.42967734\n",
      "[39,     1] loss: 0.42351118\n",
      "[40,     1] loss: 0.41739425\n",
      "[41,     1] loss: 0.41130242\n",
      "[42,     1] loss: 0.40522760\n",
      "[43,     1] loss: 0.39917138\n",
      "[44,     1] loss: 0.39318496\n",
      "[45,     1] loss: 0.38720936\n",
      "[46,     1] loss: 0.38130116\n",
      "[47,     1] loss: 0.37543151\n",
      "[48,     1] loss: 0.36954823\n",
      "[49,     1] loss: 0.36363912\n",
      "[50,     1] loss: 0.35774451\n",
      "[51,     1] loss: 0.35186851\n",
      "[52,     1] loss: 0.34604612\n",
      "[53,     1] loss: 0.34027207\n",
      "[54,     1] loss: 0.33457002\n",
      "[55,     1] loss: 0.32890204\n",
      "[56,     1] loss: 0.32326549\n",
      "[57,     1] loss: 0.31769314\n",
      "[58,     1] loss: 0.31217271\n",
      "[59,     1] loss: 0.30666870\n",
      "[60,     1] loss: 0.30118841\n",
      "[61,     1] loss: 0.29576597\n",
      "[62,     1] loss: 0.29042089\n",
      "[63,     1] loss: 0.28517848\n",
      "[64,     1] loss: 0.28001556\n",
      "[65,     1] loss: 0.27489322\n",
      "[66,     1] loss: 0.26978040\n",
      "[67,     1] loss: 0.26471955\n",
      "[68,     1] loss: 0.25973201\n",
      "[69,     1] loss: 0.25482336\n",
      "[70,     1] loss: 0.24998274\n",
      "[71,     1] loss: 0.24517718\n",
      "[72,     1] loss: 0.24045511\n",
      "[73,     1] loss: 0.23578803\n",
      "[74,     1] loss: 0.23117426\n",
      "[75,     1] loss: 0.22663338\n",
      "[76,     1] loss: 0.22214572\n",
      "[77,     1] loss: 0.21770807\n",
      "[78,     1] loss: 0.21333703\n",
      "[79,     1] loss: 0.20904502\n",
      "[80,     1] loss: 0.20482436\n",
      "[81,     1] loss: 0.20065442\n",
      "[82,     1] loss: 0.19653212\n",
      "[83,     1] loss: 0.19246797\n",
      "[84,     1] loss: 0.18849379\n",
      "[85,     1] loss: 0.18459459\n",
      "[86,     1] loss: 0.18078689\n",
      "[87,     1] loss: 0.17705446\n",
      "[88,     1] loss: 0.17339011\n",
      "[89,     1] loss: 0.16978201\n",
      "[90,     1] loss: 0.16621608\n",
      "[91,     1] loss: 0.16271879\n",
      "[92,     1] loss: 0.15928522\n",
      "[93,     1] loss: 0.15591702\n",
      "[94,     1] loss: 0.15260631\n",
      "[95,     1] loss: 0.14936006\n",
      "[96,     1] loss: 0.14617629\n",
      "[97,     1] loss: 0.14306298\n",
      "[98,     1] loss: 0.14003401\n",
      "[99,     1] loss: 0.13705619\n",
      "[100,     1] loss: 0.13412756\n",
      "[101,     1] loss: 0.13126093\n",
      "[102,     1] loss: 0.12845333\n",
      "[103,     1] loss: 0.12570715\n",
      "[104,     1] loss: 0.12302423\n",
      "[105,     1] loss: 0.12041445\n",
      "[106,     1] loss: 0.11785463\n",
      "[107,     1] loss: 0.11535287\n",
      "[108,     1] loss: 0.11291938\n",
      "[109,     1] loss: 0.11054449\n",
      "[110,     1] loss: 0.10823895\n",
      "[111,     1] loss: 0.10597466\n",
      "[112,     1] loss: 0.10375044\n",
      "[113,     1] loss: 0.10156932\n",
      "[114,     1] loss: 0.09943375\n",
      "[115,     1] loss: 0.09735292\n",
      "[116,     1] loss: 0.09531495\n",
      "[117,     1] loss: 0.09331571\n",
      "[118,     1] loss: 0.09136276\n",
      "[119,     1] loss: 0.08945049\n",
      "[120,     1] loss: 0.08757971\n",
      "[121,     1] loss: 0.08576199\n",
      "[122,     1] loss: 0.08398747\n",
      "[123,     1] loss: 0.08225075\n",
      "[124,     1] loss: 0.08054855\n",
      "[125,     1] loss: 0.07888675\n",
      "[126,     1] loss: 0.07726456\n",
      "[127,     1] loss: 0.07567663\n",
      "[128,     1] loss: 0.07413189\n",
      "[129,     1] loss: 0.07262249\n",
      "[130,     1] loss: 0.07113935\n",
      "[131,     1] loss: 0.06968725\n",
      "[132,     1] loss: 0.06827178\n",
      "[133,     1] loss: 0.06688479\n",
      "[134,     1] loss: 0.06553111\n",
      "[135,     1] loss: 0.06421348\n",
      "[136,     1] loss: 0.06292985\n",
      "[137,     1] loss: 0.06166925\n",
      "[138,     1] loss: 0.06044127\n",
      "[139,     1] loss: 0.05924410\n",
      "[140,     1] loss: 0.05807393\n",
      "[141,     1] loss: 0.05692984\n",
      "[142,     1] loss: 0.05581135\n",
      "[143,     1] loss: 0.05471994\n",
      "[144,     1] loss: 0.05365847\n",
      "[145,     1] loss: 0.05262411\n",
      "[146,     1] loss: 0.05161963\n",
      "[147,     1] loss: 0.05063544\n",
      "[148,     1] loss: 0.04967583\n",
      "[149,     1] loss: 0.04874104\n",
      "[150,     1] loss: 0.04783143\n",
      "[151,     1] loss: 0.04694277\n",
      "[152,     1] loss: 0.04607863\n",
      "[153,     1] loss: 0.04523304\n",
      "[154,     1] loss: 0.04440898\n",
      "[155,     1] loss: 0.04360551\n",
      "[156,     1] loss: 0.04282069\n",
      "[157,     1] loss: 0.04206083\n",
      "[158,     1] loss: 0.04132206\n",
      "[159,     1] loss: 0.04059970\n",
      "[160,     1] loss: 0.03989344\n",
      "[161,     1] loss: 0.03920292\n",
      "[162,     1] loss: 0.03853410\n",
      "[163,     1] loss: 0.03787662\n",
      "[164,     1] loss: 0.03723603\n",
      "[165,     1] loss: 0.03661107\n",
      "[166,     1] loss: 0.03600207\n",
      "[167,     1] loss: 0.03540618\n",
      "[168,     1] loss: 0.03482442\n",
      "[169,     1] loss: 0.03425369\n",
      "[170,     1] loss: 0.03369518\n",
      "[171,     1] loss: 0.03314901\n",
      "[172,     1] loss: 0.03261402\n",
      "[173,     1] loss: 0.03209222\n",
      "[174,     1] loss: 0.03158026\n",
      "[175,     1] loss: 0.03107773\n",
      "[176,     1] loss: 0.03058453\n",
      "[177,     1] loss: 0.03010517\n",
      "[178,     1] loss: 0.02963652\n",
      "[179,     1] loss: 0.02917818\n",
      "[180,     1] loss: 0.02873131\n",
      "[181,     1] loss: 0.02829619\n",
      "[182,     1] loss: 0.02787008\n",
      "[183,     1] loss: 0.02745391\n",
      "[184,     1] loss: 0.02704688\n",
      "[185,     1] loss: 0.02664825\n",
      "[186,     1] loss: 0.02625893\n",
      "[187,     1] loss: 0.02587784\n",
      "[188,     1] loss: 0.02550370\n",
      "[189,     1] loss: 0.02513814\n",
      "[190,     1] loss: 0.02478023\n",
      "[191,     1] loss: 0.02442906\n",
      "[192,     1] loss: 0.02408506\n",
      "[193,     1] loss: 0.02374822\n",
      "[194,     1] loss: 0.02341810\n",
      "[195,     1] loss: 0.02309553\n",
      "[196,     1] loss: 0.02277853\n",
      "[197,     1] loss: 0.02246636\n",
      "[198,     1] loss: 0.02216188\n",
      "[199,     1] loss: 0.02186338\n",
      "[200,     1] loss: 0.02157072\n",
      "[201,     1] loss: 0.02128631\n",
      "[202,     1] loss: 0.02100659\n",
      "[203,     1] loss: 0.02073125\n",
      "[204,     1] loss: 0.02046086\n",
      "[205,     1] loss: 0.02019572\n",
      "[206,     1] loss: 0.01993595\n",
      "[207,     1] loss: 0.01968110\n",
      "[208,     1] loss: 0.01943043\n",
      "[209,     1] loss: 0.01918479\n",
      "[210,     1] loss: 0.01894330\n",
      "[211,     1] loss: 0.01870663\n",
      "[212,     1] loss: 0.01847419\n",
      "[213,     1] loss: 0.01824613\n",
      "[214,     1] loss: 0.01802259\n",
      "[215,     1] loss: 0.01780243\n",
      "[216,     1] loss: 0.01758692\n",
      "[217,     1] loss: 0.01737425\n",
      "[218,     1] loss: 0.01716610\n",
      "[219,     1] loss: 0.01696097\n",
      "[220,     1] loss: 0.01675940\n",
      "[221,     1] loss: 0.01656165\n",
      "[222,     1] loss: 0.01636809\n",
      "[223,     1] loss: 0.01617688\n",
      "[224,     1] loss: 0.01598937\n",
      "[225,     1] loss: 0.01580646\n",
      "[226,     1] loss: 0.01562584\n",
      "[227,     1] loss: 0.01544902\n",
      "[228,     1] loss: 0.01527437\n",
      "[229,     1] loss: 0.01510255\n",
      "[230,     1] loss: 0.01493425\n",
      "[231,     1] loss: 0.01476824\n",
      "[232,     1] loss: 0.01460467\n",
      "[233,     1] loss: 0.01444440\n",
      "[234,     1] loss: 0.01428635\n",
      "[235,     1] loss: 0.01413071\n",
      "[236,     1] loss: 0.01397731\n",
      "[237,     1] loss: 0.01382731\n",
      "[238,     1] loss: 0.01367926\n",
      "[239,     1] loss: 0.01353291\n",
      "[240,     1] loss: 0.01338884\n",
      "[241,     1] loss: 0.01324763\n",
      "[242,     1] loss: 0.01310873\n",
      "[243,     1] loss: 0.01297179\n",
      "[244,     1] loss: 0.01283729\n",
      "[245,     1] loss: 0.01270510\n",
      "[246,     1] loss: 0.01257542\n",
      "[247,     1] loss: 0.01244685\n",
      "[248,     1] loss: 0.01231999\n",
      "[249,     1] loss: 0.01219529\n",
      "[250,     1] loss: 0.01207243\n",
      "[251,     1] loss: 0.01195109\n",
      "[252,     1] loss: 0.01183217\n",
      "[253,     1] loss: 0.01171485\n",
      "[254,     1] loss: 0.01160025\n",
      "[255,     1] loss: 0.01148748\n",
      "[256,     1] loss: 0.01137589\n",
      "[257,     1] loss: 0.01126531\n",
      "[258,     1] loss: 0.01115674\n",
      "[259,     1] loss: 0.01104983\n",
      "[260,     1] loss: 0.01094435\n",
      "[261,     1] loss: 0.01084043\n",
      "[262,     1] loss: 0.01073754\n",
      "[263,     1] loss: 0.01063637\n",
      "[264,     1] loss: 0.01053659\n",
      "[265,     1] loss: 0.01043783\n",
      "[266,     1] loss: 0.01034080\n",
      "[267,     1] loss: 0.01024518\n",
      "[268,     1] loss: 0.01015087\n",
      "[269,     1] loss: 0.01005734\n",
      "[270,     1] loss: 0.00996521\n",
      "[271,     1] loss: 0.00987405\n",
      "[272,     1] loss: 0.00978445\n",
      "[273,     1] loss: 0.00969671\n",
      "[274,     1] loss: 0.00960998\n",
      "[275,     1] loss: 0.00952402\n",
      "[276,     1] loss: 0.00943907\n",
      "[277,     1] loss: 0.00935547\n",
      "[278,     1] loss: 0.00927335\n",
      "[279,     1] loss: 0.00919204\n",
      "[280,     1] loss: 0.00911122\n",
      "[281,     1] loss: 0.00903192\n",
      "[282,     1] loss: 0.00895365\n",
      "[283,     1] loss: 0.00887618\n",
      "[284,     1] loss: 0.00880027\n",
      "[285,     1] loss: 0.00872502\n",
      "[286,     1] loss: 0.00865028\n",
      "[287,     1] loss: 0.00857689\n",
      "[288,     1] loss: 0.00850453\n",
      "[289,     1] loss: 0.00843288\n",
      "[290,     1] loss: 0.00836227\n",
      "[291,     1] loss: 0.00829235\n",
      "[292,     1] loss: 0.00822344\n",
      "[293,     1] loss: 0.00815509\n",
      "[294,     1] loss: 0.00808785\n",
      "[295,     1] loss: 0.00802176\n",
      "[296,     1] loss: 0.00795635\n",
      "[297,     1] loss: 0.00789146\n",
      "[298,     1] loss: 0.00782762\n",
      "[299,     1] loss: 0.00776447\n",
      "[300,     1] loss: 0.00770209\n",
      "[301,     1] loss: 0.00764050\n",
      "[302,     1] loss: 0.00757996\n",
      "[303,     1] loss: 0.00751972\n",
      "[304,     1] loss: 0.00746004\n",
      "[305,     1] loss: 0.00740123\n",
      "[306,     1] loss: 0.00734310\n",
      "[307,     1] loss: 0.00728567\n",
      "[308,     1] loss: 0.00722882\n",
      "[309,     1] loss: 0.00717268\n",
      "[310,     1] loss: 0.00711725\n",
      "[311,     1] loss: 0.00706252\n",
      "[312,     1] loss: 0.00700846\n",
      "[313,     1] loss: 0.00695510\n",
      "[314,     1] loss: 0.00690219\n",
      "[315,     1] loss: 0.00684973\n",
      "[316,     1] loss: 0.00679799\n",
      "[317,     1] loss: 0.00674626\n",
      "[318,     1] loss: 0.00669473\n",
      "[319,     1] loss: 0.00664414\n",
      "[320,     1] loss: 0.00659403\n",
      "[321,     1] loss: 0.00654384\n",
      "[322,     1] loss: 0.00649414\n",
      "[323,     1] loss: 0.00644533\n",
      "[324,     1] loss: 0.00639715\n",
      "[325,     1] loss: 0.00634913\n",
      "[326,     1] loss: 0.00630142\n",
      "[327,     1] loss: 0.00625420\n",
      "[328,     1] loss: 0.00620776\n",
      "[329,     1] loss: 0.00616169\n",
      "[330,     1] loss: 0.00611602\n",
      "[331,     1] loss: 0.00607098\n",
      "[332,     1] loss: 0.00602625\n",
      "[333,     1] loss: 0.00598201\n",
      "[334,     1] loss: 0.00593827\n",
      "[335,     1] loss: 0.00589616\n",
      "[336,     1] loss: 0.00585450\n",
      "[337,     1] loss: 0.00581344\n",
      "[338,     1] loss: 0.00577284\n",
      "[339,     1] loss: 0.00573244\n",
      "[340,     1] loss: 0.00569256\n",
      "[341,     1] loss: 0.00565314\n",
      "[342,     1] loss: 0.00561419\n",
      "[343,     1] loss: 0.00557566\n",
      "[344,     1] loss: 0.00553739\n",
      "[345,     1] loss: 0.00549953\n",
      "[346,     1] loss: 0.00546208\n",
      "[347,     1] loss: 0.00542502\n",
      "[348,     1] loss: 0.00538827\n",
      "[349,     1] loss: 0.00535199\n",
      "[350,     1] loss: 0.00531599\n",
      "[351,     1] loss: 0.00528040\n",
      "[352,     1] loss: 0.00524531\n",
      "[353,     1] loss: 0.00521028\n",
      "[354,     1] loss: 0.00517566\n",
      "[355,     1] loss: 0.00514160\n",
      "[356,     1] loss: 0.00510770\n",
      "[357,     1] loss: 0.00507401\n",
      "[358,     1] loss: 0.00504073\n",
      "[359,     1] loss: 0.00500787\n",
      "[360,     1] loss: 0.00497526\n",
      "[361,     1] loss: 0.00494297\n",
      "[362,     1] loss: 0.00491102\n",
      "[363,     1] loss: 0.00487936\n",
      "[364,     1] loss: 0.00484800\n",
      "[365,     1] loss: 0.00481696\n",
      "[366,     1] loss: 0.00478626\n",
      "[367,     1] loss: 0.00475573\n",
      "[368,     1] loss: 0.00472549\n",
      "[369,     1] loss: 0.00469565\n",
      "[370,     1] loss: 0.00466610\n",
      "[371,     1] loss: 0.00463673\n",
      "[372,     1] loss: 0.00460767\n",
      "[373,     1] loss: 0.00457891\n",
      "[374,     1] loss: 0.00455043\n",
      "[375,     1] loss: 0.00452216\n",
      "[376,     1] loss: 0.00449406\n",
      "[377,     1] loss: 0.00446642\n",
      "[378,     1] loss: 0.00443900\n",
      "[379,     1] loss: 0.00441176\n",
      "[380,     1] loss: 0.00438476\n",
      "[381,     1] loss: 0.00435809\n",
      "[382,     1] loss: 0.00433168\n",
      "[383,     1] loss: 0.00430541\n",
      "[384,     1] loss: 0.00427939\n",
      "[385,     1] loss: 0.00425365\n",
      "[386,     1] loss: 0.00422811\n",
      "[387,     1] loss: 0.00420279\n",
      "[388,     1] loss: 0.00417777\n",
      "[389,     1] loss: 0.00415297\n",
      "[390,     1] loss: 0.00412831\n",
      "[391,     1] loss: 0.00410390\n",
      "[392,     1] loss: 0.00407973\n",
      "[393,     1] loss: 0.00405571\n",
      "[394,     1] loss: 0.00403191\n",
      "[395,     1] loss: 0.00400838\n",
      "[396,     1] loss: 0.00398509\n",
      "[397,     1] loss: 0.00396194\n",
      "[398,     1] loss: 0.00393893\n",
      "[399,     1] loss: 0.00391618\n",
      "[400,     1] loss: 0.00389377\n",
      "[401,     1] loss: 0.00387136\n",
      "[402,     1] loss: 0.00384918\n",
      "[403,     1] loss: 0.00382730\n",
      "[404,     1] loss: 0.00380549\n",
      "[405,     1] loss: 0.00378392\n",
      "[406,     1] loss: 0.00376250\n",
      "[407,     1] loss: 0.00374130\n",
      "[408,     1] loss: 0.00372023\n",
      "[409,     1] loss: 0.00369934\n",
      "[410,     1] loss: 0.00367862\n",
      "[411,     1] loss: 0.00365804\n",
      "[412,     1] loss: 0.00363770\n",
      "[413,     1] loss: 0.00361755\n",
      "[414,     1] loss: 0.00359747\n",
      "[415,     1] loss: 0.00357762\n",
      "[416,     1] loss: 0.00355802\n",
      "[417,     1] loss: 0.00353848\n",
      "[418,     1] loss: 0.00351906\n",
      "[419,     1] loss: 0.00349987\n",
      "[420,     1] loss: 0.00348087\n",
      "[421,     1] loss: 0.00346196\n",
      "[422,     1] loss: 0.00344316\n",
      "[423,     1] loss: 0.00342463\n",
      "[424,     1] loss: 0.00340619\n",
      "[425,     1] loss: 0.00338789\n",
      "[426,     1] loss: 0.00336980\n",
      "[427,     1] loss: 0.00335181\n",
      "[428,     1] loss: 0.00333388\n",
      "[429,     1] loss: 0.00331620\n",
      "[430,     1] loss: 0.00329864\n",
      "[431,     1] loss: 0.00328126\n",
      "[432,     1] loss: 0.00326400\n",
      "[433,     1] loss: 0.00324684\n",
      "[434,     1] loss: 0.00322977\n",
      "[435,     1] loss: 0.00321287\n",
      "[436,     1] loss: 0.00319609\n",
      "[437,     1] loss: 0.00317943\n",
      "[438,     1] loss: 0.00316289\n",
      "[439,     1] loss: 0.00314659\n",
      "[440,     1] loss: 0.00313033\n",
      "[441,     1] loss: 0.00311420\n",
      "[442,     1] loss: 0.00309821\n",
      "[443,     1] loss: 0.00308237\n",
      "[444,     1] loss: 0.00306659\n",
      "[445,     1] loss: 0.00305092\n",
      "[446,     1] loss: 0.00303543\n",
      "[447,     1] loss: 0.00302003\n",
      "[448,     1] loss: 0.00300474\n",
      "[449,     1] loss: 0.00298955\n",
      "[450,     1] loss: 0.00297448\n",
      "[451,     1] loss: 0.00295953\n",
      "[452,     1] loss: 0.00294475\n",
      "[453,     1] loss: 0.00293006\n",
      "[454,     1] loss: 0.00291546\n",
      "[455,     1] loss: 0.00290093\n",
      "[456,     1] loss: 0.00288655\n",
      "[457,     1] loss: 0.00287229\n",
      "[458,     1] loss: 0.00285809\n",
      "[459,     1] loss: 0.00284400\n",
      "[460,     1] loss: 0.00283009\n",
      "[461,     1] loss: 0.00281620\n",
      "[462,     1] loss: 0.00280246\n",
      "[463,     1] loss: 0.00278885\n",
      "[464,     1] loss: 0.00277525\n",
      "[465,     1] loss: 0.00276175\n",
      "[466,     1] loss: 0.00274838\n",
      "[467,     1] loss: 0.00273511\n",
      "[468,     1] loss: 0.00272191\n",
      "[469,     1] loss: 0.00270880\n",
      "[470,     1] loss: 0.00269586\n",
      "[471,     1] loss: 0.00268301\n",
      "[472,     1] loss: 0.00267019\n",
      "[473,     1] loss: 0.00265748\n",
      "[474,     1] loss: 0.00264476\n",
      "[475,     1] loss: 0.00263232\n",
      "[476,     1] loss: 0.00261988\n",
      "[477,     1] loss: 0.00260753\n",
      "[478,     1] loss: 0.00259529\n",
      "[479,     1] loss: 0.00258314\n",
      "[480,     1] loss: 0.00257100\n",
      "[481,     1] loss: 0.00255901\n",
      "[482,     1] loss: 0.00254708\n",
      "[483,     1] loss: 0.00253524\n",
      "[484,     1] loss: 0.00252344\n",
      "[485,     1] loss: 0.00251183\n",
      "[486,     1] loss: 0.00250025\n",
      "[487,     1] loss: 0.00248862\n",
      "[488,     1] loss: 0.00247721\n",
      "[489,     1] loss: 0.00246592\n",
      "[490,     1] loss: 0.00245462\n",
      "[491,     1] loss: 0.00244338\n",
      "[492,     1] loss: 0.00243224\n",
      "[493,     1] loss: 0.00242123\n",
      "[494,     1] loss: 0.00241027\n",
      "[495,     1] loss: 0.00239938\n",
      "[496,     1] loss: 0.00238855\n",
      "[497,     1] loss: 0.00237780\n",
      "[498,     1] loss: 0.00236715\n",
      "[499,     1] loss: 0.00235658\n",
      "[500,     1] loss: 0.00234606\n",
      "[501,     1] loss: 0.00233565\n",
      "[502,     1] loss: 0.00232522\n",
      "[503,     1] loss: 0.00231492\n",
      "[504,     1] loss: 0.00230467\n",
      "[505,     1] loss: 0.00229453\n",
      "[506,     1] loss: 0.00228443\n",
      "[507,     1] loss: 0.00227438\n",
      "[508,     1] loss: 0.00226443\n",
      "[509,     1] loss: 0.00225456\n",
      "[510,     1] loss: 0.00224474\n",
      "[511,     1] loss: 0.00223498\n",
      "[512,     1] loss: 0.00222527\n",
      "[513,     1] loss: 0.00221566\n",
      "[514,     1] loss: 0.00220611\n",
      "[515,     1] loss: 0.00219660\n",
      "[516,     1] loss: 0.00218717\n",
      "[517,     1] loss: 0.00217774\n",
      "[518,     1] loss: 0.00216843\n",
      "[519,     1] loss: 0.00215914\n",
      "[520,     1] loss: 0.00214996\n",
      "[521,     1] loss: 0.00214078\n",
      "[522,     1] loss: 0.00213167\n",
      "[523,     1] loss: 0.00212263\n",
      "[524,     1] loss: 0.00211367\n",
      "[525,     1] loss: 0.00210471\n",
      "[526,     1] loss: 0.00209588\n",
      "[527,     1] loss: 0.00208709\n",
      "[528,     1] loss: 0.00207832\n",
      "[529,     1] loss: 0.00206959\n",
      "[530,     1] loss: 0.00206097\n",
      "[531,     1] loss: 0.00205239\n",
      "[532,     1] loss: 0.00204390\n",
      "[533,     1] loss: 0.00203533\n",
      "[534,     1] loss: 0.00202692\n",
      "[535,     1] loss: 0.00201856\n",
      "[536,     1] loss: 0.00201022\n",
      "[537,     1] loss: 0.00200194\n",
      "[538,     1] loss: 0.00199369\n",
      "[539,     1] loss: 0.00198553\n",
      "[540,     1] loss: 0.00197741\n",
      "[541,     1] loss: 0.00196933\n",
      "[542,     1] loss: 0.00196132\n",
      "[543,     1] loss: 0.00195331\n",
      "[544,     1] loss: 0.00194533\n",
      "[545,     1] loss: 0.00193751\n",
      "[546,     1] loss: 0.00192966\n",
      "[547,     1] loss: 0.00192184\n",
      "[548,     1] loss: 0.00191408\n",
      "[549,     1] loss: 0.00190640\n",
      "[550,     1] loss: 0.00189876\n",
      "[551,     1] loss: 0.00189114\n",
      "[552,     1] loss: 0.00188358\n",
      "[553,     1] loss: 0.00187606\n",
      "[554,     1] loss: 0.00186859\n",
      "[555,     1] loss: 0.00186121\n",
      "[556,     1] loss: 0.00185380\n",
      "[557,     1] loss: 0.00184649\n",
      "[558,     1] loss: 0.00183919\n",
      "[559,     1] loss: 0.00183193\n",
      "[560,     1] loss: 0.00182470\n",
      "[561,     1] loss: 0.00181755\n",
      "[562,     1] loss: 0.00181043\n",
      "[563,     1] loss: 0.00180332\n",
      "[564,     1] loss: 0.00179627\n",
      "[565,     1] loss: 0.00178929\n",
      "[566,     1] loss: 0.00178233\n",
      "[567,     1] loss: 0.00177538\n",
      "[568,     1] loss: 0.00176851\n",
      "[569,     1] loss: 0.00176167\n",
      "[570,     1] loss: 0.00175487\n",
      "[571,     1] loss: 0.00174811\n",
      "[572,     1] loss: 0.00174134\n",
      "[573,     1] loss: 0.00173464\n",
      "[574,     1] loss: 0.00172799\n",
      "[575,     1] loss: 0.00172137\n",
      "[576,     1] loss: 0.00171483\n",
      "[577,     1] loss: 0.00170829\n",
      "[578,     1] loss: 0.00170180\n",
      "[579,     1] loss: 0.00169528\n",
      "[580,     1] loss: 0.00168888\n",
      "[581,     1] loss: 0.00168246\n",
      "[582,     1] loss: 0.00167610\n",
      "[583,     1] loss: 0.00166981\n",
      "[584,     1] loss: 0.00166353\n",
      "[585,     1] loss: 0.00165724\n",
      "[586,     1] loss: 0.00165103\n",
      "[587,     1] loss: 0.00164487\n",
      "[588,     1] loss: 0.00163871\n",
      "[589,     1] loss: 0.00163259\n",
      "[590,     1] loss: 0.00162649\n",
      "[591,     1] loss: 0.00162041\n",
      "[592,     1] loss: 0.00161442\n",
      "[593,     1] loss: 0.00160844\n",
      "[594,     1] loss: 0.00160249\n",
      "[595,     1] loss: 0.00159657\n",
      "[596,     1] loss: 0.00159069\n",
      "[597,     1] loss: 0.00158485\n",
      "[598,     1] loss: 0.00157905\n",
      "[599,     1] loss: 0.00157323\n",
      "[600,     1] loss: 0.00156744\n",
      "[601,     1] loss: 0.00156173\n",
      "[602,     1] loss: 0.00155603\n",
      "[603,     1] loss: 0.00155036\n",
      "[604,     1] loss: 0.00154475\n",
      "[605,     1] loss: 0.00153917\n",
      "[606,     1] loss: 0.00153358\n",
      "[607,     1] loss: 0.00152800\n",
      "[608,     1] loss: 0.00152251\n",
      "[609,     1] loss: 0.00151704\n",
      "[610,     1] loss: 0.00151160\n",
      "[611,     1] loss: 0.00150616\n",
      "[612,     1] loss: 0.00150073\n",
      "[613,     1] loss: 0.00149537\n",
      "[614,     1] loss: 0.00149005\n",
      "[615,     1] loss: 0.00148476\n",
      "[616,     1] loss: 0.00147947\n",
      "[617,     1] loss: 0.00147420\n",
      "[618,     1] loss: 0.00146899\n",
      "[619,     1] loss: 0.00146379\n",
      "[620,     1] loss: 0.00145859\n",
      "[621,     1] loss: 0.00145347\n",
      "[622,     1] loss: 0.00144834\n",
      "[623,     1] loss: 0.00144324\n",
      "[624,     1] loss: 0.00143818\n",
      "[625,     1] loss: 0.00143313\n",
      "[626,     1] loss: 0.00142811\n",
      "[627,     1] loss: 0.00142312\n",
      "[628,     1] loss: 0.00141815\n",
      "[629,     1] loss: 0.00141321\n",
      "[630,     1] loss: 0.00140834\n",
      "[631,     1] loss: 0.00140346\n",
      "[632,     1] loss: 0.00139859\n",
      "[633,     1] loss: 0.00139375\n",
      "[634,     1] loss: 0.00138893\n",
      "[635,     1] loss: 0.00138413\n",
      "[636,     1] loss: 0.00137932\n",
      "[637,     1] loss: 0.00137448\n",
      "[638,     1] loss: 0.00136966\n",
      "[639,     1] loss: 0.00136491\n",
      "[640,     1] loss: 0.00136015\n",
      "[641,     1] loss: 0.00135541\n",
      "[642,     1] loss: 0.00135071\n",
      "[643,     1] loss: 0.00134603\n",
      "[644,     1] loss: 0.00134133\n",
      "[645,     1] loss: 0.00133671\n",
      "[646,     1] loss: 0.00133209\n",
      "[647,     1] loss: 0.00132749\n",
      "[648,     1] loss: 0.00132292\n",
      "[649,     1] loss: 0.00131838\n",
      "[650,     1] loss: 0.00131386\n",
      "[651,     1] loss: 0.00130937\n",
      "[652,     1] loss: 0.00130490\n",
      "[653,     1] loss: 0.00130046\n",
      "[654,     1] loss: 0.00129601\n",
      "[655,     1] loss: 0.00129160\n",
      "[656,     1] loss: 0.00128719\n",
      "[657,     1] loss: 0.00128286\n",
      "[658,     1] loss: 0.00127853\n",
      "[659,     1] loss: 0.00127419\n",
      "[660,     1] loss: 0.00126992\n",
      "[661,     1] loss: 0.00126566\n",
      "[662,     1] loss: 0.00126141\n",
      "[663,     1] loss: 0.00125719\n",
      "[664,     1] loss: 0.00125299\n",
      "[665,     1] loss: 0.00124880\n",
      "[666,     1] loss: 0.00124461\n",
      "[667,     1] loss: 0.00124049\n",
      "[668,     1] loss: 0.00123638\n",
      "[669,     1] loss: 0.00123230\n",
      "[670,     1] loss: 0.00122824\n",
      "[671,     1] loss: 0.00122415\n",
      "[672,     1] loss: 0.00122010\n",
      "[673,     1] loss: 0.00121611\n",
      "[674,     1] loss: 0.00121213\n",
      "[675,     1] loss: 0.00120815\n",
      "[676,     1] loss: 0.00120419\n",
      "[677,     1] loss: 0.00120024\n",
      "[678,     1] loss: 0.00119635\n",
      "[679,     1] loss: 0.00119246\n",
      "[680,     1] loss: 0.00118858\n",
      "[681,     1] loss: 0.00118472\n",
      "[682,     1] loss: 0.00118089\n",
      "[683,     1] loss: 0.00117705\n",
      "[684,     1] loss: 0.00117327\n",
      "[685,     1] loss: 0.00116950\n",
      "[686,     1] loss: 0.00116576\n",
      "[687,     1] loss: 0.00116201\n",
      "[688,     1] loss: 0.00115830\n",
      "[689,     1] loss: 0.00115456\n",
      "[690,     1] loss: 0.00115087\n",
      "[691,     1] loss: 0.00114720\n",
      "[692,     1] loss: 0.00114356\n",
      "[693,     1] loss: 0.00113991\n",
      "[694,     1] loss: 0.00113632\n",
      "[695,     1] loss: 0.00113266\n",
      "[696,     1] loss: 0.00112910\n",
      "[697,     1] loss: 0.00112553\n",
      "[698,     1] loss: 0.00112201\n",
      "[699,     1] loss: 0.00111844\n",
      "[700,     1] loss: 0.00111493\n",
      "[701,     1] loss: 0.00111146\n",
      "[702,     1] loss: 0.00110798\n",
      "[703,     1] loss: 0.00110451\n",
      "[704,     1] loss: 0.00110104\n",
      "[705,     1] loss: 0.00109759\n",
      "[706,     1] loss: 0.00109422\n",
      "[707,     1] loss: 0.00109083\n",
      "[708,     1] loss: 0.00108742\n",
      "[709,     1] loss: 0.00108406\n",
      "[710,     1] loss: 0.00108068\n",
      "[711,     1] loss: 0.00107736\n",
      "[712,     1] loss: 0.00107403\n",
      "[713,     1] loss: 0.00107072\n",
      "[714,     1] loss: 0.00106742\n",
      "[715,     1] loss: 0.00106415\n",
      "[716,     1] loss: 0.00106090\n",
      "[717,     1] loss: 0.00105766\n",
      "[718,     1] loss: 0.00105443\n",
      "[719,     1] loss: 0.00105120\n",
      "[720,     1] loss: 0.00104795\n",
      "[721,     1] loss: 0.00104469\n",
      "[722,     1] loss: 0.00104143\n",
      "[723,     1] loss: 0.00103817\n",
      "[724,     1] loss: 0.00103493\n",
      "[725,     1] loss: 0.00103173\n",
      "[726,     1] loss: 0.00102854\n",
      "[727,     1] loss: 0.00102530\n",
      "[728,     1] loss: 0.00102214\n",
      "[729,     1] loss: 0.00101892\n",
      "[730,     1] loss: 0.00101577\n",
      "[731,     1] loss: 0.00101264\n",
      "[732,     1] loss: 0.00100949\n",
      "[733,     1] loss: 0.00100641\n",
      "[734,     1] loss: 0.00100331\n",
      "[735,     1] loss: 0.00100022\n",
      "[736,     1] loss: 0.00099714\n",
      "[737,     1] loss: 0.00099415\n",
      "[738,     1] loss: 0.00099113\n",
      "[739,     1] loss: 0.00098815\n",
      "[740,     1] loss: 0.00098519\n",
      "[741,     1] loss: 0.00098223\n",
      "[742,     1] loss: 0.00097929\n",
      "[743,     1] loss: 0.00097636\n",
      "[744,     1] loss: 0.00097346\n",
      "[745,     1] loss: 0.00097057\n",
      "[746,     1] loss: 0.00096768\n",
      "[747,     1] loss: 0.00096481\n",
      "[748,     1] loss: 0.00096198\n",
      "[749,     1] loss: 0.00095915\n",
      "[750,     1] loss: 0.00095632\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 750\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(list(reward_net.parameters()), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(states1)))\n",
    "num_batches = len(idxs) // batch_size\n",
    "\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "   \n",
    "        t_states1 = torch.Tensor(states1).float().to(device)\n",
    "        t_states2 = torch.Tensor(states2).float().to(device)\n",
    "        t_prefs = torch.Tensor(prefs).float().to(device).unsqueeze(1)\n",
    "\n",
    "        pred_r1s, pred_r2s, pred_prefs = reward_net(t_states1, t_states2)\n",
    "        loss = criterion(pred_prefs, t_prefs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(reward_net, 'reward_network.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)\n",
    "plt.savefig('losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18471169-b9b6-4099-99c6-00d46eba7376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 0.640000 \n"
     ]
    }
   ],
   "source": [
    "reward_net = torch.load('reward_network.pt')\n",
    "reward_net.eval()\n",
    "\n",
    "import csv\n",
    "with open('data/test_rewards.csv') as file_obj:\n",
    "    reader_obj = csv.reader(file_obj)\n",
    "\n",
    "    states1 = []\n",
    "    states2 = []\n",
    "    prefs = []\n",
    "    for row in reader_obj:\n",
    "        states1.append(row[0:18])\n",
    "        states2.append(row[19:37])\n",
    "        prefs.append(row[38])\n",
    "    states1 = np.array(states1,dtype=int)\n",
    "    states2 = np.array(states2,dtype=int)\n",
    "    prefs = np.array(prefs,dtype=int)\n",
    "\n",
    "num_correct = 0.0\n",
    "for i in range(len(states1)):\n",
    "    state1 = torch.Tensor(states1[i]).to(device)\n",
    "    state2 = torch.Tensor(states2[i]).to(device)\n",
    "    pred_r1, pred_r2, pred_pref = reward_net(state1, state2)\n",
    "    pred_r1 = torch.sigmoid(pred_r1)\n",
    "    pred_r2 = torch.sigmoid(pred_r2)\n",
    "    pred_pref = torch.sigmoid(pred_pref).cpu().detach().numpy()[0]\n",
    "    if pred_pref > 0.5 and prefs[i] == 1:\n",
    "        num_correct+=1\n",
    "    elif pred_pref <= 0.5 and prefs[i] == 0:\n",
    "        num_correct+=1\n",
    "\n",
    "accuracy = num_correct / len(states1)\n",
    "print(\"Percent correct: %f \" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf5a32db-b7f2-4442-b17b-693c1457ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9600], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.6802], grad_fn=<SigmoidBackward0>)\n",
      "0.9787617\n"
     ]
    }
   ],
   "source": [
    "print(pred_r1)\n",
    "print(pred_r2)\n",
    "print(pred_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cf03fe-249d-4e6a-9097-38a18f64efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0122], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.0122], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.9998], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "best_mushroom = torch.Tensor(np.array([1,0,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,0])).to(device)\n",
    "pred_r1, pred_r2, pred_pref = reward_net(best_mushroom,best_mushroom)\n",
    "print(torch.sigmoid(pred_r1))\n",
    "print(torch.sigmoid(pred_r2))\n",
    "print(torch.sigmoid(pred_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf83b82-d48a-45a9-9d65-6e0194315b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
