{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb9baee-b622-4c37-8707-0949e11ed13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e205b6ac-00b6-4ca4-a56c-8af2711f4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "class RewardNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.reward = nn.Sequential(\n",
    "            nn.Linear(state_dim, state_dim), nn.ReLU(),\n",
    "            nn.Linear(state_dim, state_dim), nn.ReLU(),\n",
    "            nn.Linear(state_dim, 1)\n",
    "        )\n",
    "        self.pref = nn.Linear(2, 1)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state1, state2):\n",
    "        r1 = self.reward(state1)\n",
    "        r2 = self.reward(state2)\n",
    "        comp = torch.squeeze(torch.stack([r1,r2], dim=1))\n",
    "        pref = self.pref(comp)\n",
    "        return r1, r2, pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd635ce5-260d-4f51-a206-0eabf9823d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RewardNet(\n",
       "  (reward): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=18, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=18, out_features=18, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=18, out_features=1, bias=True)\n",
       "  )\n",
       "  (pref): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim = 18\n",
    "\n",
    "reward_net = RewardNet(state_dim)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "reward_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "441683da-6be2-4173-a7bc-dab41edc92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data/train_rewards500.csv') as file_obj:\n",
    "    reader_obj = csv.reader(file_obj)\n",
    "\n",
    "    states1 = []\n",
    "    states2 = []\n",
    "    prefs = []\n",
    "    for row in reader_obj:\n",
    "        states1.append(row[0:18])\n",
    "        states2.append(row[19:37])\n",
    "        prefs.append(row[38])\n",
    "    states1 = np.array(states1,dtype=int)\n",
    "    states2 = np.array(states2,dtype=int)\n",
    "    prefs = np.array(prefs,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66c6bce4-dfac-459e-9188-a428808dd0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.69445956\n",
      "[2,     1] loss: 0.67478549\n",
      "[3,     1] loss: 0.65744358\n",
      "[4,     1] loss: 0.63852173\n",
      "[5,     1] loss: 0.61659920\n",
      "[6,     1] loss: 0.59031898\n",
      "[7,     1] loss: 0.55884409\n",
      "[8,     1] loss: 0.52467579\n",
      "[9,     1] loss: 0.49055538\n",
      "[10,     1] loss: 0.45885351\n",
      "[11,     1] loss: 0.43160295\n",
      "[12,     1] loss: 0.40957212\n",
      "[13,     1] loss: 0.39132467\n",
      "[14,     1] loss: 0.37490264\n",
      "[15,     1] loss: 0.35903946\n",
      "[16,     1] loss: 0.34357610\n",
      "[17,     1] loss: 0.32860270\n",
      "[18,     1] loss: 0.31386596\n",
      "[19,     1] loss: 0.29923943\n",
      "[20,     1] loss: 0.28471333\n",
      "[21,     1] loss: 0.27027339\n",
      "[22,     1] loss: 0.25574464\n",
      "[23,     1] loss: 0.24117868\n",
      "[24,     1] loss: 0.22645532\n",
      "[25,     1] loss: 0.21169171\n",
      "[26,     1] loss: 0.19721271\n",
      "[27,     1] loss: 0.18302670\n",
      "[28,     1] loss: 0.16919193\n",
      "[29,     1] loss: 0.15586205\n",
      "[30,     1] loss: 0.14307502\n",
      "[31,     1] loss: 0.13091090\n",
      "[32,     1] loss: 0.11944825\n",
      "[33,     1] loss: 0.10868520\n",
      "[34,     1] loss: 0.09864108\n",
      "[35,     1] loss: 0.08933251\n",
      "[36,     1] loss: 0.08072403\n",
      "[37,     1] loss: 0.07287832\n",
      "[38,     1] loss: 0.06580140\n",
      "[39,     1] loss: 0.05938143\n",
      "[40,     1] loss: 0.05353342\n",
      "[41,     1] loss: 0.04823168\n",
      "[42,     1] loss: 0.04342984\n",
      "[43,     1] loss: 0.03914784\n",
      "[44,     1] loss: 0.03536139\n",
      "[45,     1] loss: 0.03203848\n",
      "[46,     1] loss: 0.02913290\n",
      "[47,     1] loss: 0.02655522\n",
      "[48,     1] loss: 0.02427840\n",
      "[49,     1] loss: 0.02226174\n",
      "[50,     1] loss: 0.02044764\n",
      "[51,     1] loss: 0.01882151\n",
      "[52,     1] loss: 0.01735318\n",
      "[53,     1] loss: 0.01603513\n",
      "[54,     1] loss: 0.01485972\n",
      "[55,     1] loss: 0.01379899\n",
      "[56,     1] loss: 0.01283518\n",
      "[57,     1] loss: 0.01196547\n",
      "[58,     1] loss: 0.01118231\n",
      "[59,     1] loss: 0.01046236\n",
      "[60,     1] loss: 0.00979345\n",
      "[61,     1] loss: 0.00917479\n",
      "[62,     1] loss: 0.00860525\n",
      "[63,     1] loss: 0.00808033\n",
      "[64,     1] loss: 0.00759434\n",
      "[65,     1] loss: 0.00714989\n",
      "[66,     1] loss: 0.00674113\n",
      "[67,     1] loss: 0.00636597\n",
      "[68,     1] loss: 0.00601984\n",
      "[69,     1] loss: 0.00569999\n",
      "[70,     1] loss: 0.00540659\n",
      "[71,     1] loss: 0.00513526\n",
      "[72,     1] loss: 0.00488424\n",
      "[73,     1] loss: 0.00465074\n",
      "[74,     1] loss: 0.00443311\n",
      "[75,     1] loss: 0.00423007\n",
      "[76,     1] loss: 0.00404071\n",
      "[77,     1] loss: 0.00386324\n",
      "[78,     1] loss: 0.00369738\n",
      "[79,     1] loss: 0.00354145\n",
      "[80,     1] loss: 0.00339440\n",
      "[81,     1] loss: 0.00325634\n",
      "[82,     1] loss: 0.00312628\n",
      "[83,     1] loss: 0.00300317\n",
      "[84,     1] loss: 0.00288645\n",
      "[85,     1] loss: 0.00277634\n",
      "[86,     1] loss: 0.00267251\n",
      "[87,     1] loss: 0.00257454\n",
      "[88,     1] loss: 0.00248086\n",
      "[89,     1] loss: 0.00239002\n",
      "[90,     1] loss: 0.00230361\n",
      "[91,     1] loss: 0.00222078\n",
      "[92,     1] loss: 0.00213945\n",
      "[93,     1] loss: 0.00206402\n",
      "[94,     1] loss: 0.00199336\n",
      "[95,     1] loss: 0.00192677\n",
      "[96,     1] loss: 0.00186392\n",
      "[97,     1] loss: 0.00180432\n",
      "[98,     1] loss: 0.00174687\n",
      "[99,     1] loss: 0.00169215\n",
      "[100,     1] loss: 0.00164009\n",
      "[101,     1] loss: 0.00159089\n",
      "[102,     1] loss: 0.00154358\n",
      "[103,     1] loss: 0.00149723\n",
      "[104,     1] loss: 0.00145184\n",
      "[105,     1] loss: 0.00140769\n",
      "[106,     1] loss: 0.00136543\n",
      "[107,     1] loss: 0.00132545\n",
      "[108,     1] loss: 0.00128721\n",
      "[109,     1] loss: 0.00125070\n",
      "[110,     1] loss: 0.00121559\n",
      "[111,     1] loss: 0.00118195\n",
      "[112,     1] loss: 0.00115028\n",
      "[113,     1] loss: 0.00112009\n",
      "[114,     1] loss: 0.00109116\n",
      "[115,     1] loss: 0.00106319\n",
      "[116,     1] loss: 0.00103481\n",
      "[117,     1] loss: 0.00100718\n",
      "[118,     1] loss: 0.00098055\n",
      "[119,     1] loss: 0.00095485\n",
      "[120,     1] loss: 0.00093045\n",
      "[121,     1] loss: 0.00090722\n",
      "[122,     1] loss: 0.00088495\n",
      "[123,     1] loss: 0.00086266\n",
      "[124,     1] loss: 0.00084098\n",
      "[125,     1] loss: 0.00082024\n",
      "[126,     1] loss: 0.00080039\n",
      "[127,     1] loss: 0.00078132\n",
      "[128,     1] loss: 0.00076304\n",
      "[129,     1] loss: 0.00074556\n",
      "[130,     1] loss: 0.00072884\n",
      "[131,     1] loss: 0.00071270\n",
      "[132,     1] loss: 0.00069711\n",
      "[133,     1] loss: 0.00068204\n",
      "[134,     1] loss: 0.00066746\n",
      "[135,     1] loss: 0.00065325\n",
      "[136,     1] loss: 0.00063942\n",
      "[137,     1] loss: 0.00062601\n",
      "[138,     1] loss: 0.00061293\n",
      "[139,     1] loss: 0.00060022\n",
      "[140,     1] loss: 0.00058788\n",
      "[141,     1] loss: 0.00057602\n",
      "[142,     1] loss: 0.00056446\n",
      "[143,     1] loss: 0.00055323\n",
      "[144,     1] loss: 0.00054231\n",
      "[145,     1] loss: 0.00053173\n",
      "[146,     1] loss: 0.00052144\n",
      "[147,     1] loss: 0.00051145\n",
      "[148,     1] loss: 0.00050182\n",
      "[149,     1] loss: 0.00049257\n",
      "[150,     1] loss: 0.00048359\n",
      "[151,     1] loss: 0.00047485\n",
      "[152,     1] loss: 0.00046633\n",
      "[153,     1] loss: 0.00045804\n",
      "[154,     1] loss: 0.00044995\n",
      "[155,     1] loss: 0.00044208\n",
      "[156,     1] loss: 0.00043442\n",
      "[157,     1] loss: 0.00042696\n",
      "[158,     1] loss: 0.00041967\n",
      "[159,     1] loss: 0.00041255\n",
      "[160,     1] loss: 0.00040559\n",
      "[161,     1] loss: 0.00039879\n",
      "[162,     1] loss: 0.00039216\n",
      "[163,     1] loss: 0.00038569\n",
      "[164,     1] loss: 0.00037937\n",
      "[165,     1] loss: 0.00037320\n",
      "[166,     1] loss: 0.00036717\n",
      "[167,     1] loss: 0.00036125\n",
      "[168,     1] loss: 0.00035540\n",
      "[169,     1] loss: 0.00034968\n",
      "[170,     1] loss: 0.00034407\n",
      "[171,     1] loss: 0.00033859\n",
      "[172,     1] loss: 0.00033323\n",
      "[173,     1] loss: 0.00032800\n",
      "[174,     1] loss: 0.00032286\n",
      "[175,     1] loss: 0.00031783\n",
      "[176,     1] loss: 0.00031290\n",
      "[177,     1] loss: 0.00030809\n",
      "[178,     1] loss: 0.00030338\n",
      "[179,     1] loss: 0.00029878\n",
      "[180,     1] loss: 0.00029428\n",
      "[181,     1] loss: 0.00028990\n",
      "[182,     1] loss: 0.00028560\n",
      "[183,     1] loss: 0.00028140\n",
      "[184,     1] loss: 0.00027729\n",
      "[185,     1] loss: 0.00027327\n",
      "[186,     1] loss: 0.00026933\n",
      "[187,     1] loss: 0.00026547\n",
      "[188,     1] loss: 0.00026168\n",
      "[189,     1] loss: 0.00025797\n",
      "[190,     1] loss: 0.00025431\n",
      "[191,     1] loss: 0.00025073\n",
      "[192,     1] loss: 0.00024721\n",
      "[193,     1] loss: 0.00024376\n",
      "[194,     1] loss: 0.00024037\n",
      "[195,     1] loss: 0.00023705\n",
      "[196,     1] loss: 0.00023380\n",
      "[197,     1] loss: 0.00023061\n",
      "[198,     1] loss: 0.00022747\n",
      "[199,     1] loss: 0.00022440\n",
      "[200,     1] loss: 0.00022137\n",
      "[201,     1] loss: 0.00021841\n",
      "[202,     1] loss: 0.00021550\n",
      "[203,     1] loss: 0.00021265\n",
      "[204,     1] loss: 0.00020985\n",
      "[205,     1] loss: 0.00020710\n",
      "[206,     1] loss: 0.00020439\n",
      "[207,     1] loss: 0.00020174\n",
      "[208,     1] loss: 0.00019914\n",
      "[209,     1] loss: 0.00019657\n",
      "[210,     1] loss: 0.00019406\n",
      "[211,     1] loss: 0.00019159\n",
      "[212,     1] loss: 0.00018916\n",
      "[213,     1] loss: 0.00018677\n",
      "[214,     1] loss: 0.00018443\n",
      "[215,     1] loss: 0.00018212\n",
      "[216,     1] loss: 0.00017985\n",
      "[217,     1] loss: 0.00017761\n",
      "[218,     1] loss: 0.00017540\n",
      "[219,     1] loss: 0.00017323\n",
      "[220,     1] loss: 0.00017109\n",
      "[221,     1] loss: 0.00016898\n",
      "[222,     1] loss: 0.00016691\n",
      "[223,     1] loss: 0.00016488\n",
      "[224,     1] loss: 0.00016287\n",
      "[225,     1] loss: 0.00016090\n",
      "[226,     1] loss: 0.00015896\n",
      "[227,     1] loss: 0.00015705\n",
      "[228,     1] loss: 0.00015517\n",
      "[229,     1] loss: 0.00015333\n",
      "[230,     1] loss: 0.00015151\n",
      "[231,     1] loss: 0.00014972\n",
      "[232,     1] loss: 0.00014796\n",
      "[233,     1] loss: 0.00014623\n",
      "[234,     1] loss: 0.00014452\n",
      "[235,     1] loss: 0.00014284\n",
      "[236,     1] loss: 0.00014118\n",
      "[237,     1] loss: 0.00013954\n",
      "[238,     1] loss: 0.00013793\n",
      "[239,     1] loss: 0.00013634\n",
      "[240,     1] loss: 0.00013477\n",
      "[241,     1] loss: 0.00013323\n",
      "[242,     1] loss: 0.00013172\n",
      "[243,     1] loss: 0.00013022\n",
      "[244,     1] loss: 0.00012875\n",
      "[245,     1] loss: 0.00012730\n",
      "[246,     1] loss: 0.00012588\n",
      "[247,     1] loss: 0.00012447\n",
      "[248,     1] loss: 0.00012308\n",
      "[249,     1] loss: 0.00012172\n",
      "[250,     1] loss: 0.00012038\n",
      "[251,     1] loss: 0.00011906\n",
      "[252,     1] loss: 0.00011776\n",
      "[253,     1] loss: 0.00011647\n",
      "[254,     1] loss: 0.00011521\n",
      "[255,     1] loss: 0.00011396\n",
      "[256,     1] loss: 0.00011273\n",
      "[257,     1] loss: 0.00011152\n",
      "[258,     1] loss: 0.00011032\n",
      "[259,     1] loss: 0.00010914\n",
      "[260,     1] loss: 0.00010798\n",
      "[261,     1] loss: 0.00010683\n",
      "[262,     1] loss: 0.00010571\n",
      "[263,     1] loss: 0.00010459\n",
      "[264,     1] loss: 0.00010349\n",
      "[265,     1] loss: 0.00010241\n",
      "[266,     1] loss: 0.00010134\n",
      "[267,     1] loss: 0.00010028\n",
      "[268,     1] loss: 0.00009924\n",
      "[269,     1] loss: 0.00009822\n",
      "[270,     1] loss: 0.00009720\n",
      "[271,     1] loss: 0.00009620\n",
      "[272,     1] loss: 0.00009521\n",
      "[273,     1] loss: 0.00009424\n",
      "[274,     1] loss: 0.00009327\n",
      "[275,     1] loss: 0.00009232\n",
      "[276,     1] loss: 0.00009139\n",
      "[277,     1] loss: 0.00009046\n",
      "[278,     1] loss: 0.00008955\n",
      "[279,     1] loss: 0.00008865\n",
      "[280,     1] loss: 0.00008776\n",
      "[281,     1] loss: 0.00008689\n",
      "[282,     1] loss: 0.00008602\n",
      "[283,     1] loss: 0.00008516\n",
      "[284,     1] loss: 0.00008432\n",
      "[285,     1] loss: 0.00008348\n",
      "[286,     1] loss: 0.00008265\n",
      "[287,     1] loss: 0.00008184\n",
      "[288,     1] loss: 0.00008103\n",
      "[289,     1] loss: 0.00008023\n",
      "[290,     1] loss: 0.00007945\n",
      "[291,     1] loss: 0.00007868\n",
      "[292,     1] loss: 0.00007791\n",
      "[293,     1] loss: 0.00007715\n",
      "[294,     1] loss: 0.00007640\n",
      "[295,     1] loss: 0.00007567\n",
      "[296,     1] loss: 0.00007494\n",
      "[297,     1] loss: 0.00007422\n",
      "[298,     1] loss: 0.00007351\n",
      "[299,     1] loss: 0.00007280\n",
      "[300,     1] loss: 0.00007211\n",
      "[301,     1] loss: 0.00007143\n",
      "[302,     1] loss: 0.00007075\n",
      "[303,     1] loss: 0.00007008\n",
      "[304,     1] loss: 0.00006942\n",
      "[305,     1] loss: 0.00006877\n",
      "[306,     1] loss: 0.00006812\n",
      "[307,     1] loss: 0.00006748\n",
      "[308,     1] loss: 0.00006685\n",
      "[309,     1] loss: 0.00006623\n",
      "[310,     1] loss: 0.00006561\n",
      "[311,     1] loss: 0.00006500\n",
      "[312,     1] loss: 0.00006440\n",
      "[313,     1] loss: 0.00006381\n",
      "[314,     1] loss: 0.00006322\n",
      "[315,     1] loss: 0.00006264\n",
      "[316,     1] loss: 0.00006206\n",
      "[317,     1] loss: 0.00006150\n",
      "[318,     1] loss: 0.00006094\n",
      "[319,     1] loss: 0.00006038\n",
      "[320,     1] loss: 0.00005983\n",
      "[321,     1] loss: 0.00005929\n",
      "[322,     1] loss: 0.00005876\n",
      "[323,     1] loss: 0.00005822\n",
      "[324,     1] loss: 0.00005770\n",
      "[325,     1] loss: 0.00005719\n",
      "[326,     1] loss: 0.00005667\n",
      "[327,     1] loss: 0.00005617\n",
      "[328,     1] loss: 0.00005567\n",
      "[329,     1] loss: 0.00005517\n",
      "[330,     1] loss: 0.00005468\n",
      "[331,     1] loss: 0.00005420\n",
      "[332,     1] loss: 0.00005371\n",
      "[333,     1] loss: 0.00005324\n",
      "[334,     1] loss: 0.00005276\n",
      "[335,     1] loss: 0.00005230\n",
      "[336,     1] loss: 0.00005183\n",
      "[337,     1] loss: 0.00005137\n",
      "[338,     1] loss: 0.00005092\n",
      "[339,     1] loss: 0.00005048\n",
      "[340,     1] loss: 0.00005003\n",
      "[341,     1] loss: 0.00004960\n",
      "[342,     1] loss: 0.00004916\n",
      "[343,     1] loss: 0.00004874\n",
      "[344,     1] loss: 0.00004831\n",
      "[345,     1] loss: 0.00004790\n",
      "[346,     1] loss: 0.00004748\n",
      "[347,     1] loss: 0.00004707\n",
      "[348,     1] loss: 0.00004667\n",
      "[349,     1] loss: 0.00004627\n",
      "[350,     1] loss: 0.00004587\n",
      "[351,     1] loss: 0.00004548\n",
      "[352,     1] loss: 0.00004509\n",
      "[353,     1] loss: 0.00004470\n",
      "[354,     1] loss: 0.00004433\n",
      "[355,     1] loss: 0.00004395\n",
      "[356,     1] loss: 0.00004358\n",
      "[357,     1] loss: 0.00004321\n",
      "[358,     1] loss: 0.00004284\n",
      "[359,     1] loss: 0.00004248\n",
      "[360,     1] loss: 0.00004213\n",
      "[361,     1] loss: 0.00004177\n",
      "[362,     1] loss: 0.00004142\n",
      "[363,     1] loss: 0.00004107\n",
      "[364,     1] loss: 0.00004073\n",
      "[365,     1] loss: 0.00004039\n",
      "[366,     1] loss: 0.00004005\n",
      "[367,     1] loss: 0.00003972\n",
      "[368,     1] loss: 0.00003939\n",
      "[369,     1] loss: 0.00003906\n",
      "[370,     1] loss: 0.00003873\n",
      "[371,     1] loss: 0.00003841\n",
      "[372,     1] loss: 0.00003810\n",
      "[373,     1] loss: 0.00003778\n",
      "[374,     1] loss: 0.00003747\n",
      "[375,     1] loss: 0.00003716\n",
      "[376,     1] loss: 0.00003686\n",
      "[377,     1] loss: 0.00003656\n",
      "[378,     1] loss: 0.00003626\n",
      "[379,     1] loss: 0.00003596\n",
      "[380,     1] loss: 0.00003567\n",
      "[381,     1] loss: 0.00003538\n",
      "[382,     1] loss: 0.00003509\n",
      "[383,     1] loss: 0.00003481\n",
      "[384,     1] loss: 0.00003452\n",
      "[385,     1] loss: 0.00003424\n",
      "[386,     1] loss: 0.00003396\n",
      "[387,     1] loss: 0.00003368\n",
      "[388,     1] loss: 0.00003341\n",
      "[389,     1] loss: 0.00003314\n",
      "[390,     1] loss: 0.00003287\n",
      "[391,     1] loss: 0.00003260\n",
      "[392,     1] loss: 0.00003234\n",
      "[393,     1] loss: 0.00003208\n",
      "[394,     1] loss: 0.00003182\n",
      "[395,     1] loss: 0.00003157\n",
      "[396,     1] loss: 0.00003131\n",
      "[397,     1] loss: 0.00003106\n",
      "[398,     1] loss: 0.00003081\n",
      "[399,     1] loss: 0.00003057\n",
      "[400,     1] loss: 0.00003033\n",
      "[401,     1] loss: 0.00003008\n",
      "[402,     1] loss: 0.00002985\n",
      "[403,     1] loss: 0.00002961\n",
      "[404,     1] loss: 0.00002937\n",
      "[405,     1] loss: 0.00002914\n",
      "[406,     1] loss: 0.00002891\n",
      "[407,     1] loss: 0.00002869\n",
      "[408,     1] loss: 0.00002846\n",
      "[409,     1] loss: 0.00002824\n",
      "[410,     1] loss: 0.00002802\n",
      "[411,     1] loss: 0.00002780\n",
      "[412,     1] loss: 0.00002758\n",
      "[413,     1] loss: 0.00002736\n",
      "[414,     1] loss: 0.00002715\n",
      "[415,     1] loss: 0.00002694\n",
      "[416,     1] loss: 0.00002673\n",
      "[417,     1] loss: 0.00002653\n",
      "[418,     1] loss: 0.00002632\n",
      "[419,     1] loss: 0.00002612\n",
      "[420,     1] loss: 0.00002592\n",
      "[421,     1] loss: 0.00002572\n",
      "[422,     1] loss: 0.00002552\n",
      "[423,     1] loss: 0.00002532\n",
      "[424,     1] loss: 0.00002513\n",
      "[425,     1] loss: 0.00002494\n",
      "[426,     1] loss: 0.00002474\n",
      "[427,     1] loss: 0.00002456\n",
      "[428,     1] loss: 0.00002437\n",
      "[429,     1] loss: 0.00002418\n",
      "[430,     1] loss: 0.00002400\n",
      "[431,     1] loss: 0.00002381\n",
      "[432,     1] loss: 0.00002363\n",
      "[433,     1] loss: 0.00002345\n",
      "[434,     1] loss: 0.00002327\n",
      "[435,     1] loss: 0.00002310\n",
      "[436,     1] loss: 0.00002292\n",
      "[437,     1] loss: 0.00002275\n",
      "[438,     1] loss: 0.00002257\n",
      "[439,     1] loss: 0.00002239\n",
      "[440,     1] loss: 0.00002222\n",
      "[441,     1] loss: 0.00002204\n",
      "[442,     1] loss: 0.00002187\n",
      "[443,     1] loss: 0.00002169\n",
      "[444,     1] loss: 0.00002152\n",
      "[445,     1] loss: 0.00002135\n",
      "[446,     1] loss: 0.00002118\n",
      "[447,     1] loss: 0.00002102\n",
      "[448,     1] loss: 0.00002086\n",
      "[449,     1] loss: 0.00002070\n",
      "[450,     1] loss: 0.00002054\n",
      "[451,     1] loss: 0.00002038\n",
      "[452,     1] loss: 0.00002022\n",
      "[453,     1] loss: 0.00002007\n",
      "[454,     1] loss: 0.00001991\n",
      "[455,     1] loss: 0.00001976\n",
      "[456,     1] loss: 0.00001961\n",
      "[457,     1] loss: 0.00001946\n",
      "[458,     1] loss: 0.00001932\n",
      "[459,     1] loss: 0.00001917\n",
      "[460,     1] loss: 0.00001902\n",
      "[461,     1] loss: 0.00001888\n",
      "[462,     1] loss: 0.00001874\n",
      "[463,     1] loss: 0.00001860\n",
      "[464,     1] loss: 0.00001846\n",
      "[465,     1] loss: 0.00001832\n",
      "[466,     1] loss: 0.00001818\n",
      "[467,     1] loss: 0.00001804\n",
      "[468,     1] loss: 0.00001791\n",
      "[469,     1] loss: 0.00001778\n",
      "[470,     1] loss: 0.00001764\n",
      "[471,     1] loss: 0.00001751\n",
      "[472,     1] loss: 0.00001737\n",
      "[473,     1] loss: 0.00001724\n",
      "[474,     1] loss: 0.00001711\n",
      "[475,     1] loss: 0.00001698\n",
      "[476,     1] loss: 0.00001685\n",
      "[477,     1] loss: 0.00001672\n",
      "[478,     1] loss: 0.00001660\n",
      "[479,     1] loss: 0.00001647\n",
      "[480,     1] loss: 0.00001635\n",
      "[481,     1] loss: 0.00001623\n",
      "[482,     1] loss: 0.00001611\n",
      "[483,     1] loss: 0.00001599\n",
      "[484,     1] loss: 0.00001587\n",
      "[485,     1] loss: 0.00001575\n",
      "[486,     1] loss: 0.00001563\n",
      "[487,     1] loss: 0.00001551\n",
      "[488,     1] loss: 0.00001540\n",
      "[489,     1] loss: 0.00001528\n",
      "[490,     1] loss: 0.00001517\n",
      "[491,     1] loss: 0.00001506\n",
      "[492,     1] loss: 0.00001495\n",
      "[493,     1] loss: 0.00001484\n",
      "[494,     1] loss: 0.00001473\n",
      "[495,     1] loss: 0.00001462\n",
      "[496,     1] loss: 0.00001451\n",
      "[497,     1] loss: 0.00001441\n",
      "[498,     1] loss: 0.00001430\n",
      "[499,     1] loss: 0.00001420\n",
      "[500,     1] loss: 0.00001409\n",
      "[501,     1] loss: 0.00001399\n",
      "[502,     1] loss: 0.00001389\n",
      "[503,     1] loss: 0.00001379\n",
      "[504,     1] loss: 0.00001369\n",
      "[505,     1] loss: 0.00001359\n",
      "[506,     1] loss: 0.00001349\n",
      "[507,     1] loss: 0.00001339\n",
      "[508,     1] loss: 0.00001329\n",
      "[509,     1] loss: 0.00001320\n",
      "[510,     1] loss: 0.00001310\n",
      "[511,     1] loss: 0.00001301\n",
      "[512,     1] loss: 0.00001292\n",
      "[513,     1] loss: 0.00001282\n",
      "[514,     1] loss: 0.00001273\n",
      "[515,     1] loss: 0.00001264\n",
      "[516,     1] loss: 0.00001254\n",
      "[517,     1] loss: 0.00001245\n",
      "[518,     1] loss: 0.00001236\n",
      "[519,     1] loss: 0.00001227\n",
      "[520,     1] loss: 0.00001218\n",
      "[521,     1] loss: 0.00001209\n",
      "[522,     1] loss: 0.00001201\n",
      "[523,     1] loss: 0.00001192\n",
      "[524,     1] loss: 0.00001183\n",
      "[525,     1] loss: 0.00001175\n",
      "[526,     1] loss: 0.00001167\n",
      "[527,     1] loss: 0.00001158\n",
      "[528,     1] loss: 0.00001150\n",
      "[529,     1] loss: 0.00001142\n",
      "[530,     1] loss: 0.00001133\n",
      "[531,     1] loss: 0.00001125\n",
      "[532,     1] loss: 0.00001117\n",
      "[533,     1] loss: 0.00001109\n",
      "[534,     1] loss: 0.00001102\n",
      "[535,     1] loss: 0.00001094\n",
      "[536,     1] loss: 0.00001086\n",
      "[537,     1] loss: 0.00001078\n",
      "[538,     1] loss: 0.00001071\n",
      "[539,     1] loss: 0.00001063\n",
      "[540,     1] loss: 0.00001055\n",
      "[541,     1] loss: 0.00001048\n",
      "[542,     1] loss: 0.00001041\n",
      "[543,     1] loss: 0.00001033\n",
      "[544,     1] loss: 0.00001026\n",
      "[545,     1] loss: 0.00001019\n",
      "[546,     1] loss: 0.00001012\n",
      "[547,     1] loss: 0.00001005\n",
      "[548,     1] loss: 0.00000998\n",
      "[549,     1] loss: 0.00000991\n",
      "[550,     1] loss: 0.00000984\n",
      "[551,     1] loss: 0.00000977\n",
      "[552,     1] loss: 0.00000970\n",
      "[553,     1] loss: 0.00000964\n",
      "[554,     1] loss: 0.00000957\n",
      "[555,     1] loss: 0.00000950\n",
      "[556,     1] loss: 0.00000943\n",
      "[557,     1] loss: 0.00000937\n",
      "[558,     1] loss: 0.00000931\n",
      "[559,     1] loss: 0.00000924\n",
      "[560,     1] loss: 0.00000917\n",
      "[561,     1] loss: 0.00000911\n",
      "[562,     1] loss: 0.00000905\n",
      "[563,     1] loss: 0.00000899\n",
      "[564,     1] loss: 0.00000892\n",
      "[565,     1] loss: 0.00000886\n",
      "[566,     1] loss: 0.00000880\n",
      "[567,     1] loss: 0.00000874\n",
      "[568,     1] loss: 0.00000868\n",
      "[569,     1] loss: 0.00000862\n",
      "[570,     1] loss: 0.00000856\n",
      "[571,     1] loss: 0.00000851\n",
      "[572,     1] loss: 0.00000845\n",
      "[573,     1] loss: 0.00000839\n",
      "[574,     1] loss: 0.00000834\n",
      "[575,     1] loss: 0.00000828\n",
      "[576,     1] loss: 0.00000822\n",
      "[577,     1] loss: 0.00000817\n",
      "[578,     1] loss: 0.00000811\n",
      "[579,     1] loss: 0.00000806\n",
      "[580,     1] loss: 0.00000800\n",
      "[581,     1] loss: 0.00000795\n",
      "[582,     1] loss: 0.00000789\n",
      "[583,     1] loss: 0.00000784\n",
      "[584,     1] loss: 0.00000779\n",
      "[585,     1] loss: 0.00000773\n",
      "[586,     1] loss: 0.00000768\n",
      "[587,     1] loss: 0.00000763\n",
      "[588,     1] loss: 0.00000758\n",
      "[589,     1] loss: 0.00000753\n",
      "[590,     1] loss: 0.00000748\n",
      "[591,     1] loss: 0.00000742\n",
      "[592,     1] loss: 0.00000737\n",
      "[593,     1] loss: 0.00000732\n",
      "[594,     1] loss: 0.00000726\n",
      "[595,     1] loss: 0.00000721\n",
      "[596,     1] loss: 0.00000716\n",
      "[597,     1] loss: 0.00000711\n",
      "[598,     1] loss: 0.00000706\n",
      "[599,     1] loss: 0.00000701\n",
      "[600,     1] loss: 0.00000695\n",
      "[601,     1] loss: 0.00000690\n",
      "[602,     1] loss: 0.00000685\n",
      "[603,     1] loss: 0.00000681\n",
      "[604,     1] loss: 0.00000676\n",
      "[605,     1] loss: 0.00000671\n",
      "[606,     1] loss: 0.00000666\n",
      "[607,     1] loss: 0.00000661\n",
      "[608,     1] loss: 0.00000656\n",
      "[609,     1] loss: 0.00000652\n",
      "[610,     1] loss: 0.00000647\n",
      "[611,     1] loss: 0.00000642\n",
      "[612,     1] loss: 0.00000637\n",
      "[613,     1] loss: 0.00000633\n",
      "[614,     1] loss: 0.00000628\n",
      "[615,     1] loss: 0.00000624\n",
      "[616,     1] loss: 0.00000619\n",
      "[617,     1] loss: 0.00000615\n",
      "[618,     1] loss: 0.00000611\n",
      "[619,     1] loss: 0.00000606\n",
      "[620,     1] loss: 0.00000602\n",
      "[621,     1] loss: 0.00000598\n",
      "[622,     1] loss: 0.00000594\n",
      "[623,     1] loss: 0.00000589\n",
      "[624,     1] loss: 0.00000585\n",
      "[625,     1] loss: 0.00000581\n",
      "[626,     1] loss: 0.00000577\n",
      "[627,     1] loss: 0.00000573\n",
      "[628,     1] loss: 0.00000569\n",
      "[629,     1] loss: 0.00000565\n",
      "[630,     1] loss: 0.00000561\n",
      "[631,     1] loss: 0.00000557\n",
      "[632,     1] loss: 0.00000553\n",
      "[633,     1] loss: 0.00000549\n",
      "[634,     1] loss: 0.00000546\n",
      "[635,     1] loss: 0.00000542\n",
      "[636,     1] loss: 0.00000538\n",
      "[637,     1] loss: 0.00000534\n",
      "[638,     1] loss: 0.00000531\n",
      "[639,     1] loss: 0.00000527\n",
      "[640,     1] loss: 0.00000524\n",
      "[641,     1] loss: 0.00000520\n",
      "[642,     1] loss: 0.00000516\n",
      "[643,     1] loss: 0.00000513\n",
      "[644,     1] loss: 0.00000509\n",
      "[645,     1] loss: 0.00000505\n",
      "[646,     1] loss: 0.00000502\n",
      "[647,     1] loss: 0.00000498\n",
      "[648,     1] loss: 0.00000494\n",
      "[649,     1] loss: 0.00000490\n",
      "[650,     1] loss: 0.00000487\n",
      "[651,     1] loss: 0.00000483\n",
      "[652,     1] loss: 0.00000479\n",
      "[653,     1] loss: 0.00000476\n",
      "[654,     1] loss: 0.00000472\n",
      "[655,     1] loss: 0.00000469\n",
      "[656,     1] loss: 0.00000465\n",
      "[657,     1] loss: 0.00000462\n",
      "[658,     1] loss: 0.00000459\n",
      "[659,     1] loss: 0.00000455\n",
      "[660,     1] loss: 0.00000452\n",
      "[661,     1] loss: 0.00000449\n",
      "[662,     1] loss: 0.00000446\n",
      "[663,     1] loss: 0.00000442\n",
      "[664,     1] loss: 0.00000439\n",
      "[665,     1] loss: 0.00000436\n",
      "[666,     1] loss: 0.00000433\n",
      "[667,     1] loss: 0.00000430\n",
      "[668,     1] loss: 0.00000427\n",
      "[669,     1] loss: 0.00000424\n",
      "[670,     1] loss: 0.00000421\n",
      "[671,     1] loss: 0.00000418\n",
      "[672,     1] loss: 0.00000415\n",
      "[673,     1] loss: 0.00000412\n",
      "[674,     1] loss: 0.00000409\n",
      "[675,     1] loss: 0.00000406\n",
      "[676,     1] loss: 0.00000403\n",
      "[677,     1] loss: 0.00000400\n",
      "[678,     1] loss: 0.00000397\n",
      "[679,     1] loss: 0.00000395\n",
      "[680,     1] loss: 0.00000392\n",
      "[681,     1] loss: 0.00000389\n",
      "[682,     1] loss: 0.00000386\n",
      "[683,     1] loss: 0.00000383\n",
      "[684,     1] loss: 0.00000381\n",
      "[685,     1] loss: 0.00000378\n",
      "[686,     1] loss: 0.00000376\n",
      "[687,     1] loss: 0.00000373\n",
      "[688,     1] loss: 0.00000370\n",
      "[689,     1] loss: 0.00000368\n",
      "[690,     1] loss: 0.00000365\n",
      "[691,     1] loss: 0.00000363\n",
      "[692,     1] loss: 0.00000360\n",
      "[693,     1] loss: 0.00000358\n",
      "[694,     1] loss: 0.00000355\n",
      "[695,     1] loss: 0.00000353\n",
      "[696,     1] loss: 0.00000351\n",
      "[697,     1] loss: 0.00000348\n",
      "[698,     1] loss: 0.00000346\n",
      "[699,     1] loss: 0.00000344\n",
      "[700,     1] loss: 0.00000341\n",
      "[701,     1] loss: 0.00000339\n",
      "[702,     1] loss: 0.00000337\n",
      "[703,     1] loss: 0.00000335\n",
      "[704,     1] loss: 0.00000332\n",
      "[705,     1] loss: 0.00000330\n",
      "[706,     1] loss: 0.00000328\n",
      "[707,     1] loss: 0.00000326\n",
      "[708,     1] loss: 0.00000324\n",
      "[709,     1] loss: 0.00000322\n",
      "[710,     1] loss: 0.00000319\n",
      "[711,     1] loss: 0.00000317\n",
      "[712,     1] loss: 0.00000315\n",
      "[713,     1] loss: 0.00000313\n",
      "[714,     1] loss: 0.00000311\n",
      "[715,     1] loss: 0.00000309\n",
      "[716,     1] loss: 0.00000307\n",
      "[717,     1] loss: 0.00000305\n",
      "[718,     1] loss: 0.00000303\n",
      "[719,     1] loss: 0.00000301\n",
      "[720,     1] loss: 0.00000299\n",
      "[721,     1] loss: 0.00000297\n",
      "[722,     1] loss: 0.00000295\n",
      "[723,     1] loss: 0.00000293\n",
      "[724,     1] loss: 0.00000291\n",
      "[725,     1] loss: 0.00000289\n",
      "[726,     1] loss: 0.00000287\n",
      "[727,     1] loss: 0.00000285\n",
      "[728,     1] loss: 0.00000283\n",
      "[729,     1] loss: 0.00000281\n",
      "[730,     1] loss: 0.00000279\n",
      "[731,     1] loss: 0.00000277\n",
      "[732,     1] loss: 0.00000276\n",
      "[733,     1] loss: 0.00000274\n",
      "[734,     1] loss: 0.00000272\n",
      "[735,     1] loss: 0.00000270\n",
      "[736,     1] loss: 0.00000269\n",
      "[737,     1] loss: 0.00000267\n",
      "[738,     1] loss: 0.00000265\n",
      "[739,     1] loss: 0.00000263\n",
      "[740,     1] loss: 0.00000262\n",
      "[741,     1] loss: 0.00000260\n",
      "[742,     1] loss: 0.00000258\n",
      "[743,     1] loss: 0.00000257\n",
      "[744,     1] loss: 0.00000255\n",
      "[745,     1] loss: 0.00000253\n",
      "[746,     1] loss: 0.00000252\n",
      "[747,     1] loss: 0.00000250\n",
      "[748,     1] loss: 0.00000249\n",
      "[749,     1] loss: 0.00000247\n",
      "[750,     1] loss: 0.00000246\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 750\n",
    "batch_size = 50\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(list(reward_net.parameters()), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(states1)))\n",
    "num_batches = len(idxs) // batch_size\n",
    "\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "   \n",
    "        t_states1 = torch.Tensor(states1).float().to(device)\n",
    "        t_states2 = torch.Tensor(states2).float().to(device)\n",
    "        t_prefs = torch.Tensor(prefs).float().to(device).unsqueeze(1)\n",
    "\n",
    "        pred_r1s, pred_r2s, pred_prefs = reward_net(t_states1, t_states2)\n",
    "        loss = criterion(pred_prefs, t_prefs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(reward_net, 'reward_network.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)\n",
    "plt.savefig('losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18471169-b9b6-4099-99c6-00d46eba7376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 1.000000 \n"
     ]
    }
   ],
   "source": [
    "reward_net = torch.load('reward_network.pt')\n",
    "reward_net.eval()\n",
    "\n",
    "import csv\n",
    "with open('data/test_rewards.csv') as file_obj:\n",
    "    reader_obj = csv.reader(file_obj)\n",
    "\n",
    "    states1 = []\n",
    "    states2 = []\n",
    "    prefs = []\n",
    "    for row in reader_obj:\n",
    "        states1.append(row[0:18])\n",
    "        states2.append(row[19:37])\n",
    "        prefs.append(row[38])\n",
    "    states1 = np.array(states1,dtype=int)\n",
    "    states2 = np.array(states2,dtype=int)\n",
    "    prefs = np.array(prefs,dtype=int)\n",
    "\n",
    "num_correct = 0.0\n",
    "for i in range(len(states1)):\n",
    "    state1 = torch.Tensor(states1[i]).to(device)\n",
    "    state2 = torch.Tensor(states2[i]).to(device)\n",
    "    pred_r1, pred_r2, pred_pref = reward_net(state1, state2)\n",
    "    pred_r1 = torch.sigmoid(pred_r1)\n",
    "    pred_r2 = torch.sigmoid(pred_r2)\n",
    "    pred_pref = torch.sigmoid(pred_pref).cpu().detach().numpy()[0]\n",
    "    if pred_pref > 0.5 and prefs[i] == 1:\n",
    "        num_correct+=1\n",
    "    elif pred_pref <= 0.5 and prefs[i] == 0:\n",
    "        num_correct+=1\n",
    "\n",
    "accuracy = num_correct / len(states1)\n",
    "print(\"Percent correct: %f \" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a32db-b7f2-4442-b17b-693c1457ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_r1)\n",
    "print(pred_r2)\n",
    "print(pred_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf03fe-249d-4e6a-9097-38a18f64efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mushroom = torch.Tensor(np.array([1,0,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,0])).to(device)\n",
    "pred_r1, pred_r2, pred_pref = reward_net(best_mushroom,best_mushroom)\n",
    "print(torch.sigmoid(pred_r1))\n",
    "print(torch.sigmoid(pred_r2))\n",
    "print(torch.sigmoid(pred_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf83b82-d48a-45a9-9d65-6e0194315b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
